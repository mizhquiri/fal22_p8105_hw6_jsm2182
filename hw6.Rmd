---
title: "HW 6"
author: "Jennifer Mizhquiri"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(mgcv)
library(rvest)
library(httr)
library(modelr)

library(viridis)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

# Problem 1 

# Problem 2 

```{r, echo = FALSE, warning = FALSE, message = FALSE}
homicide_rawdf = read_csv("./data/homicide-data.csv")
```


Steps: 

1. Cleaned the data

- created a `city_state_ variable`
- created a variable for `solved` homicides 
- removed Dallas, TX; Phoenix, AZ; and Kansas City, MO – these don’t report victim race. Also omit Tulsa, AL 
- `victim_race` was restricted to `white` or `black`
- `victim_age` is numeric

```{r, echo = FALSE}
homicide_cleandf = 
  homicide_rawdf %>% 
  mutate(
    city_state = str_c(city,", ", state), 
    solved = case_when(disposition == "Closed by arrest" ~ 1,
                          disposition != "Closed by arrest" ~ 0)
  ) %>% 
  filter(
    city_state != "Dallas, Tx", 
    city_state != "Phoenix, AZ",
    city_state != "Kansas City, MO", 
    city_state != "Tulsa, AL"
  ) %>% 
  filter(
    victim_race == "White" | victim_race == "Black"
  ) %>% 
  mutate(
    victim_age = as.numeric(victim_age),
    victim_race = fct_relevel(victim_race, "white")
  ) %>% 
  relocate(city_state)
```

2. Use the glm function for Baltimore 

- Isolated data related to Baltimore, MD
```{r, echo = FALSE}

baltimore_df = 
  homicide_cleandf %>% 
  filter(
    city_state == "Baltimore, MD"
  )


```
For the city of Baltimore, MD, use the glm function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors.  Save the output of glm as an R object;apply the broom::tidy to this object

```{r, echo = FALSE}
fit_logistic = 
  baltimore_df %>% 
  glm(solved ~ victim_age + victim_sex + victim_race, data = ., family = binomial()) %>% 
  broom::tidy(conf.int = TRUE, conf.level = 0.95)

fit_logistic

```
* recall the estimates above are log odds ratios 

Obtain the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing male victims to female victims keeping all other variables fixed. 

```{r, echo = FALSE}
fit_logistic %>% 
  mutate(OR = exp(estimate)) %>% 
  select(term, OR, conf.low, conf.high) %>% 
  knitr::kable(digits = 3)


```


In Baltimore, MD, men who are the victims of homicides are 0.426 as likely to have a solved homicide compared to women, adjusting for victim race (white vs. black) and victim age.We are 95% confident that the true value lies between -1.1264 to -0.5842. 


3. Now run glm for each of the cities in your dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing male victims to female victims. Do this within a “tidy” pipeline, making use of purrr::map, list columns, and unnest as necessary to create a dataframe with estimated ORs and CIs for each city.


```{r, echo = FALSE}
homicide_plotdf = 
homicide_cleandf %>% 
  nest(df = -city_state) %>% 
  mutate(
    models = map(.x = df, ~glm(solved ~ victim_age + victim_sex + victim_race, data = ., family = binomial())),
    results = map(.x = models, ~broom::tidy(.x, conf.int = TRUE, conf.level = 0.95))
  ) %>% 
  unnest(results) %>% 
  filter(
    term == "victim_sexMale"
  ) %>% 
  mutate(
    city_state = as.factor(city_state),
    city_state = fct_reorder(city_state, estimate)
  )

head(homicide_plotdf)
```

Create a plot that shows the estimated ORs and CIs for each city. Organize cities according to estimated OR, and comment on the plot.


```{r, echo = FALSE}
homicide_plotdf %>% 
 ggplot(aes(x = city_state, y = estimate)) + 
  geom_boxplot() + 
  geom_errorbar(
    aes(ymin = conf.low, ymax = conf.high), width = .2, 
    position = position_dodge(.9)
  ) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) + 
  theme(legend.position = "right") + 
  labs(
    x = "Cities",
    y = "ORs of Solved Homicides",
    title = "Solved Homicide OR Estimates & CI for Men to Women in Select Cities (n = 50) "
    ) 
```

The odds ratios of solved homicides demonstrate a wide range in odds of having a solved homicide versus an unsolved/open homicide case for men compared to women across several cities, when adjusting for victim race (black vs white) and victim age. Interestingly, in most cities, the odds of having a solved homicide versus an unsolved/open homicide for a male victim is lower than the odds of having a solved homicide versus an unsolved/open homicide for a female victim (when adjusting for victim age/race). There is a wide range of confidence intervals, however, so that might warrant more inspection and other factors might be more closely evaluated. 

# Problem 3 



```{r, echo = FALSE, warning = FALSE, message = FALSE}
birth_rawdf = read_csv("./data/birthweight.csv")
```


Steps: 

1. Cleaned the data

- ensured all categorical variables were factors in the data
- removed missing data

```{r, echo = FALSE}
birth_cleandf = 
  birth_rawdf %>% 
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(frace),
    mrace = as.factor(mrace)
  ) %>% 
  drop_na()
```


2. I propose the following model:

Y = B(babysex) + B(smoken) + B(wtgain) + B(smoken) + B(mrace2) + B(mrace3) + B(mrace4) + B(wtgain) + Error


```{r, echo = FALSE}

fit_mymodel = lm(bwt ~ babysex + smoken + mrace + wtgain, data = birth_cleandf)


lm(bwt ~ babysex + smoken + mrace + wtgain, data = birth_cleandf) %>% broom::tidy() %>% 
    knitr::kable(2, caption = "Above: My Model")


lm(bwt ~ blength + gaweeks, data = birth_cleandf) %>% broom::tidy() %>% 
    knitr::kable(2, caption = "Above: Model No1:  length at birth and gestational age as predictors (main effects only)")


lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex, data = birth_cleandf) %>% broom::tidy() %>% 
    knitr::kable(2, caption = "Above: Model No2: head circumference, length, sex, and all interactions (including the three-way interaction) between these")

```

_Modeling process_

- I selected factors that I recognized from the literature may correlate to birth weight, such as maternal smoking status, maternal race, and the mother's weight gain during pregnancy. I also added baby sex. 


_Plot residuals vs predictors in my model_

- the plotted residuals and predictors indicate there is some clustering going on. I am content to proceed with my model for the purposes of the homework, however, I may have wanted to inspect my model some more using e.g. correlation matrices and inspected the variables for more theorized collinearity. 

```{r, echo = FALSE}
birth_cleandf %>%
  add_predictions(fit_mymodel) %>% 
  add_residuals(fit_mymodel) %>% 
  ggplot(aes(x = pred, y = resid)) + geom_point(alpha = 0.5) + geom_hline(yintercept = 0) + 
  labs(
    x = "Predicted Valudes",
    y = "Residual Values",
    title = "Plotted Predicted vs Residual Values in My Model"
    ) 
  
```


_Comparing the three models_


```{r, echo = FALSE}

model_df = 
  crossv_mc(birth_cleandf, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble),
  )


model_df = 
  model_df %>% 
  mutate(
    fit_mymodel = map(.x = train, ~lm(bwt ~ babysex + smoken + mrace + wtgain, data = .x)),
    fit_no1 =    map(.x = train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    fit_no2 = map(.x = train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex, data = .x))
  ) %>% 
  mutate(
    rmse_mymodel = map2_dbl(.x = fit_mymodel, .y = test, ~rmse(model = .x, data = .y)),
    rmse_no1 =    map2_dbl(.x = fit_no1, .y = test, ~rmse(model = .x, data = .y)),
    rmse_no2 = map2_dbl(.x = fit_no2, .y = test, ~rmse(model = .x, data = .y))
  )

```

```{r, echo = FALSE}
model_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  ggplot(aes(x = model, y = rmse)) +
  geom_boxplot() + 
  labs(
    x = "Models",
    y = "RMSE",
    title = "Comparing RMSEs of Each Model"
    ) 
```


As a result, I can see visually that model #2 is the better model on average as it has a lower RMSE. My model has a relatively much higher RMSE. This is not surprising given the above noted issues with my model selection.